{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw location data - used the Nominatim Geolocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_raw_data = {}\n",
    "def get_raw_data():\n",
    "    \"\"\"Loop through file, obtain reverse lookup location metadata, \n",
    "        store in dict and write to file.\"\"\"\n",
    "    \n",
    "    geolocator = Nominatim(user_agent=\"test_API\")\n",
    "\n",
    "    df = pd.read_csv('lat_lon.csv')\n",
    "    \n",
    "    #Remove duplicates to reduce API calls\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        lat_lon = str(row['lat_four']) + \", \"+ str(row['lng_four'])\n",
    "        location = geolocator.reverse(lat_lon)\n",
    "        location_raw_data[lat_lon] = location.raw\n",
    "        print(lat_lon)\n",
    "        time.sleep(1)\n",
    "\n",
    "    pickle.dump(location_raw_data, open(\"loc_raw_data.p\", \"wb\"))\n",
    "    print (location_raw_data)\n",
    "\n",
    "    \n",
    "\n",
    "def load_pickle_data():\n",
    "    raw_data = pickle.load(open (\"loc_raw_data.p\", \"rb\"))\n",
    "    return raw_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL / DATA CLEANING\n",
    "The goal here is to have every lat/lon coord placed in a state district.\n",
    "\n",
    "Next we will aim to place each coord in at least ONE of the following:\n",
    "- City\n",
    "- Town\n",
    "- Village\n",
    "- Hamlet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############### ETL STEPS - Uncomment as necessary  ##################\n",
    "\n",
    "def map_address_to_lat_long(row):\n",
    "    \"\"\"Looks for the address element of each lat lon element\n",
    "       Return a series containing the CITY, TOWN, VILLAGE and STATE_DISTRICT\n",
    "       Elements of the address\"\"\"\n",
    "    \n",
    "    lat_lon = str(row['lat_four']) + \", \"+ str(row['lng_four'])\n",
    "\n",
    "    city = raw_location_data[lat_lon]['address'].get('city', None)\n",
    "    town = raw_location_data[lat_lon]['address'].get('town', None)\n",
    "    village = raw_location_data[lat_lon]['address'].get('village', None)\n",
    "    hamlet = raw_location_data[lat_lon]['address'].get('hamlet', None)\n",
    "    state_district = raw_location_data[lat_lon]['address'].get('state_district', None)\n",
    "    \n",
    "    return pd.Series([city, town, village, hamlet, state_district], \n",
    "                     index=['city', 'town', 'village', 'hamlet', 'state_district'])\n",
    "\n",
    "#Get raw location data for each of the lat/long coords\n",
    "#get_raw_data()\n",
    "\n",
    "#Load raw data\n",
    "raw_location_data = load_pickle_data()\n",
    "\n",
    "df = pd.read_csv('lat_lon.csv')\n",
    "\n",
    "#We are interested in the City, Town, State_District each of the trips takes place in.\n",
    "df[['city','town', 'village', 'hamlet', 'state_district']] = df.apply(map_address_to_lat_long, axis=1)\n",
    "\n",
    "#Load this to CSV, check results\n",
    "#df.to_csv('lat_lon_full.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing State Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'place_id': 70147557, 'licence': 'Data Â© OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright', 'osm_type': 'way', 'osm_id': 6008815, 'lat': '53.1791206458678', 'lon': '-2.94376740910927', 'display_name': 'Bradshaw Avenue, Saltney, Saltney Ferry, Flintshire, Wales, CH4 0AZ, UK', 'address': {'road': 'Bradshaw Avenue', 'suburb': 'Saltney', 'village': 'Saltney Ferry', 'county': 'Flintshire', 'state': 'Wales', 'postcode': 'CH4 0AZ', 'country': 'UK', 'country_code': 'gb'}, 'boundingbox': ['53.179013', '53.1791409', '-2.9446901', '-2.9434533']}\n"
     ]
    }
   ],
   "source": [
    "#I noticed there was one element that didn't have a state_district.\n",
    "df_not_mapped = df[df['state_district'].isnull()]\n",
    "\n",
    "# There was no clues in the raw data...\n",
    "print(raw_location_data[\"53.1794, -2.9438\"])\n",
    "\n",
    "#So I just manually looked up the site and fixed it...\n",
    "\n",
    "#Manually ammended this element\n",
    "df.loc[df_not_mapped.index[0], 'state_district'] = \"North West\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat_four</th>\n",
       "      <th>lng_four</th>\n",
       "      <th>city</th>\n",
       "      <th>town</th>\n",
       "      <th>village</th>\n",
       "      <th>hamlet</th>\n",
       "      <th>state_district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>52.9474</td>\n",
       "      <td>-1.0006</td>\n",
       "      <td>Rushcliffe</td>\n",
       "      <td>Nottinghamshire</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>East Midlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>52.8415</td>\n",
       "      <td>-1.0332</td>\n",
       "      <td>Rushcliffe</td>\n",
       "      <td>Nottinghamshire</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>East Midlands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lat_four  lng_four        city             town village hamlet  \\\n",
       "16    52.9474   -1.0006  Rushcliffe  Nottinghamshire    None   None   \n",
       "160   52.8415   -1.0332  Rushcliffe  Nottinghamshire    None   None   \n",
       "\n",
       "    state_district  \n",
       "16   East Midlands  \n",
       "160  East Midlands  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['city'].notnull()) & (df['town'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Again I looked at the raw data and there was no clues, so I manually looked these two up on Googlemaps\n",
    "\n",
    "#print(location_raw_data[\"52.9474, -1.0006\"])\n",
    "#print(location_raw_data[\"52.8415, -1.0332\"])\n",
    "\n",
    "df.loc[df['lat_four'] == 52.9474, 'city'] = None\n",
    "df.loc[df['lat_four'] == 52.9474, 'town'] = \"Radcliffe on Trent\"\n",
    "\n",
    "df.loc[df['lat_four'] == 52.8415, 'city'] = None\n",
    "df.loc[df['lat_four'] == 52.8415, 'town'] = \"Bunny\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets verify the dataset is complete..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [lat_four, lng_four, city, town, village, hamlet, state_district, location_count]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df['location_count'] = df[['city','town', 'village', 'hamlet']].apply(lambda x: x.count(), axis=1)\n",
    "print(df[df['location_count'] > 1])\n",
    "df = df.drop('location_count', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('lat_lon_full.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
