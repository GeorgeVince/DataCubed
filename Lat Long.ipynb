{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location_raw_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw location data - used the Nominatim Geolocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_raw_data():\n",
    "    \"\"\"Loop through file, obtain reverse lookup location metadata, \n",
    "        store in dict and write to file.\"\"\"\n",
    "    \n",
    "    geolocator = Nominatim(user_agent=\"test_API\")\n",
    "\n",
    "    df = pd.read_csv('lat_lon.csv')\n",
    "    \n",
    "    #Remove duplicates to reduce API calls\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        lat_lon = str(row['lat_four']) + \", \"+ str(row['lng_four'])\n",
    "        location = geolocator.reverse(lat_lon)\n",
    "        location_raw_data[lat_lon] = location.raw\n",
    "        print(lat_lon)\n",
    "        time.sleep(1)\n",
    "\n",
    "    pickle.dump(location_raw_data, open(\"loc_raw_data.p\", \"wb\"))\n",
    "    print (location_raw_data)\n",
    "\n",
    "    \n",
    "\n",
    "def load_pickle_data():\n",
    "    raw_data = pickle.load(open (\"loc_raw_data.p\", \"rb\"))\n",
    "    return raw_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL / DATA CLEANING\n",
    "The goal here is to have every lat/lon coord placed in a state district.\n",
    "\n",
    "Next we will aim to place each coord in at least ONE of the following:\n",
    "- City\n",
    "- Town\n",
    "- Village\n",
    "- Hamlet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############### ETL STEPS - Uncomment as necessary  ##################\n",
    "\n",
    "def map_address_to_lat_long(row):\n",
    "    \"\"\"Looks for the address element of each lat lon element\n",
    "       Return a series containing the CITY, TOWN, VILLAGE and STATE_DISTRICT\n",
    "       Elements of the address\"\"\"\n",
    "    \n",
    "    lat_lon = str(row['lat_four']) + \", \"+ str(row['lng_four'])\n",
    "\n",
    "    city = raw_location_data[lat_lon]['address'].get('city', None)\n",
    "    town = raw_location_data[lat_lon]['address'].get('town', None)\n",
    "    village = raw_location_data[lat_lon]['address'].get('village', None)\n",
    "    hamlet = raw_location_data[lat_lon]['address'].get('hamlet', None)\n",
    "    state_district = raw_location_data[lat_lon]['address'].get('state_district', None)\n",
    "    \n",
    "    return pd.Series([city, town, village, hamlet, state_district], \n",
    "                     index=['city', 'town', 'village', 'hamlet', 'state_district'])\n",
    "\n",
    "#Get raw location data for each of the lat/long coords\n",
    "#get_raw_data()\n",
    "\n",
    "#Load raw data\n",
    "raw_location_data = load_pickle_data()\n",
    "\n",
    "df = pd.read_csv('lat_lon.csv')\n",
    "\n",
    "#We are interested in the City, Town, State_District each of the trips takes place in.\n",
    "df[['city','town', 'village', 'hamlet', 'state_district']] = df.apply(map_address_to_lat_long, axis=1)\n",
    "\n",
    "#Load this to CSV, check results\n",
    "#df.to_csv('lat_lon_full.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing State Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'place_id': 70147557, 'licence': 'Data Â© OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright', 'osm_type': 'way', 'osm_id': 6008815, 'lat': '53.1791206458678', 'lon': '-2.94376740910927', 'display_name': 'Bradshaw Avenue, Saltney, Saltney Ferry, Flintshire, Wales, CH4 0AZ, UK', 'address': {'road': 'Bradshaw Avenue', 'suburb': 'Saltney', 'village': 'Saltney Ferry', 'county': 'Flintshire', 'state': 'Wales', 'postcode': 'CH4 0AZ', 'country': 'UK', 'country_code': 'gb'}, 'boundingbox': ['53.179013', '53.1791409', '-2.9446901', '-2.9434533']}\n"
     ]
    }
   ],
   "source": [
    "#I noticed there was one element that didn't have a state_district.\n",
    "df_not_mapped = df[df['state_district'].isnull()]\n",
    "\n",
    "# There was no clues in the raw data...\n",
    "print(location_raw_data[\"53.1794, -2.9438\"])\n",
    "\n",
    "#So I just manually looked up the site and fixed it...\n",
    "\n",
    "#Manually ammended this element\n",
    "df.loc[df_not_mapped.index[0], 'state_district'] = \"North West\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
